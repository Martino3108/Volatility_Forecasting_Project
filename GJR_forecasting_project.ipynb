{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the book data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "import glob\n",
    "list_order_book_file_train = glob.glob('book_train.parquet/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80485c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b48e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computimg logreturn for every time id\n",
    "def logreturn_per_timeid(file_path, stock_id):\n",
    "    df_book_data = pd.read_parquet(file_path)\n",
    "    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n",
    "                                      df_book_data['bid_size1']+ df_book_data[\n",
    "                                  'ask_size1'])\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].transform(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    log_returns_dict = {\n",
    "        f'stockid{stock_id}_timeid{time_id}': group['log_return'].values\n",
    "        for time_id, group in df_book_data.groupby('time_id')\n",
    "    }\n",
    "\n",
    "    return log_returns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9503c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book_train.parquet/stock_id=17', 'book_train.parquet/stock_id=28', 'book_train.parquet/stock_id=10', 'book_train.parquet/stock_id=26', 'book_train.parquet/stock_id=19', 'book_train.parquet/stock_id=21', 'book_train.parquet/stock_id=75', 'book_train.parquet/stock_id=81', 'book_train.parquet/stock_id=86', 'book_train.parquet/stock_id=72', 'book_train.parquet/stock_id=44', 'book_train.parquet/stock_id=88', 'book_train.parquet/stock_id=43', 'book_train.parquet/stock_id=20', 'book_train.parquet/stock_id=27', 'book_train.parquet/stock_id=18', 'book_train.parquet/stock_id=11', 'book_train.parquet/stock_id=16', 'book_train.parquet/stock_id=29', 'book_train.parquet/stock_id=89', 'book_train.parquet/stock_id=42', 'book_train.parquet/stock_id=73', 'book_train.parquet/stock_id=87', 'book_train.parquet/stock_id=80', 'book_train.parquet/stock_id=74', 'book_train.parquet/stock_id=103', 'book_train.parquet/stock_id=104', 'book_train.parquet/stock_id=105', 'book_train.parquet/stock_id=102', 'book_train.parquet/stock_id=120', 'book_train.parquet/stock_id=118', 'book_train.parquet/stock_id=111', 'book_train.parquet/stock_id=116', 'book_train.parquet/stock_id=110', 'book_train.parquet/stock_id=119', 'book_train.parquet/stock_id=126', 'book_train.parquet/stock_id=7', 'book_train.parquet/stock_id=56', 'book_train.parquet/stock_id=69', 'book_train.parquet/stock_id=51', 'book_train.parquet/stock_id=0', 'book_train.parquet/stock_id=67', 'book_train.parquet/stock_id=93', 'book_train.parquet/stock_id=58', 'book_train.parquet/stock_id=9', 'book_train.parquet/stock_id=94', 'book_train.parquet/stock_id=60', 'book_train.parquet/stock_id=34', 'book_train.parquet/stock_id=33', 'book_train.parquet/stock_id=61', 'book_train.parquet/stock_id=95', 'book_train.parquet/stock_id=66', 'book_train.parquet/stock_id=8', 'book_train.parquet/stock_id=59', 'book_train.parquet/stock_id=1', 'book_train.parquet/stock_id=50', 'book_train.parquet/stock_id=6', 'book_train.parquet/stock_id=68', 'book_train.parquet/stock_id=32', 'book_train.parquet/stock_id=35', 'book_train.parquet/stock_id=85', 'book_train.parquet/stock_id=76', 'book_train.parquet/stock_id=82', 'book_train.parquet/stock_id=40', 'book_train.parquet/stock_id=78', 'book_train.parquet/stock_id=47', 'book_train.parquet/stock_id=13', 'book_train.parquet/stock_id=14', 'book_train.parquet/stock_id=22', 'book_train.parquet/stock_id=46', 'book_train.parquet/stock_id=41', 'book_train.parquet/stock_id=48', 'book_train.parquet/stock_id=83', 'book_train.parquet/stock_id=77', 'book_train.parquet/stock_id=70', 'book_train.parquet/stock_id=84', 'book_train.parquet/stock_id=23', 'book_train.parquet/stock_id=15', 'book_train.parquet/stock_id=107', 'book_train.parquet/stock_id=100', 'book_train.parquet/stock_id=109', 'book_train.parquet/stock_id=108', 'book_train.parquet/stock_id=101', 'book_train.parquet/stock_id=124', 'book_train.parquet/stock_id=123', 'book_train.parquet/stock_id=115', 'book_train.parquet/stock_id=112', 'book_train.parquet/stock_id=113', 'book_train.parquet/stock_id=114', 'book_train.parquet/stock_id=122', 'book_train.parquet/stock_id=125', 'book_train.parquet/stock_id=30', 'book_train.parquet/stock_id=37', 'book_train.parquet/stock_id=39', 'book_train.parquet/stock_id=52', 'book_train.parquet/stock_id=3', 'book_train.parquet/stock_id=99', 'book_train.parquet/stock_id=4', 'book_train.parquet/stock_id=55', 'book_train.parquet/stock_id=97', 'book_train.parquet/stock_id=63', 'book_train.parquet/stock_id=64', 'book_train.parquet/stock_id=90', 'book_train.parquet/stock_id=38', 'book_train.parquet/stock_id=36', 'book_train.parquet/stock_id=31', 'book_train.parquet/stock_id=62', 'book_train.parquet/stock_id=96', 'book_train.parquet/stock_id=5', 'book_train.parquet/stock_id=2', 'book_train.parquet/stock_id=53', 'book_train.parquet/stock_id=98']\n"
     ]
    }
   ],
   "source": [
    "print(list_order_book_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating for each stock\n",
    "def logreturn_per_stock(list_file):\n",
    "    all_log_returns = {}\n",
    "\n",
    "    for file in list_file:\n",
    "        stock_id = int(os.path.basename(file).split('=')[1].split('.')[0])\n",
    "        one_stock_log = logreturn_per_timeid(file, stock_id)\n",
    "        all_log_returns.update(one_stock_log)\n",
    "\n",
    "    return all_log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ditionary with all the log return vectors\n",
    "all_logreturn = logreturn_per_stock(list_file=list_order_book_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply GJR in each time id rescaling to avoid numerical instability\n",
    "data = []\n",
    "success_count=0\n",
    "for key, vector in all_logreturn.items():\n",
    "    parts = key.replace(\"stockid\", \"\").split(\"_timeid\")\n",
    "    stock_id = int(parts[0])\n",
    "    time_id = int(parts[1])\n",
    "    model = arch_model(vector* 0.3*1e5, vol='GARCH', p=1, o=1,q=1, dist='normal')\n",
    "    res = model.fit(disp='off')\n",
    "    sigma_GJR = np.nan \n",
    "    if res.optimization_result.success:\n",
    "        success_count += 1 \n",
    "        sigma_GJR = res.conditional_volatility[-1]\n",
    "    \n",
    "    data.append({\n",
    "        \"stock_id\": stock_id,\n",
    "        \"time_id\": time_id,\n",
    "        \"sigma_GJR\": sigma_GJR\n",
    "    })\n",
    "df_GJR = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42610c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428430\n",
      "0.9988296513200228\n"
     ]
    }
   ],
   "source": [
    "#visualize how many GJR converges out of all the time ids\n",
    "print(success_count)\n",
    "print(success_count/len(all_logreturn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stock_id  time_id  sigma_GJR\n",
      "0             17        5   0.000191\n",
      "1             17       11   0.000126\n",
      "2             17       16   0.000239\n",
      "3             17       31   0.000146\n",
      "4             17       62   0.000264\n",
      "...          ...      ...        ...\n",
      "428927        98    32751   0.000208\n",
      "428928        98    32753   0.000072\n",
      "428929        98    32758   0.000168\n",
      "428930        98    32763   0.000203\n",
      "428931        98    32767   0.000149\n",
      "\n",
      "[428932 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_GJR['sigma_GJR']=df_GJR['sigma_GJR']/(0.3*1e5)\n",
    "print(df_GJR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the train dataset with volatility target for each stock and time id\n",
    "# add GJR column\n",
    "train = pd.read_csv('train.csv')\n",
    "df_joined = train.merge(\n",
    "    df_GJR[['stock_id', 'time_id', 'sigma_GJR']],\n",
    "    on=['stock_id', 'time_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ace88cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stock_id  time_id    target  sigma_GJR\n",
      "0              0        5  0.004136   0.000207\n",
      "1              0       11  0.001445   0.000202\n",
      "2              0       16  0.002168   0.000165\n",
      "3              0       31  0.002195   0.000224\n",
      "4              0       62  0.001747   0.000343\n",
      "...          ...      ...       ...        ...\n",
      "428927       126    32751  0.003461   0.000185\n",
      "428928       126    32753  0.003113   0.000355\n",
      "428929       126    32758  0.004070   0.000248\n",
      "428930       126    32763  0.003357   0.000173\n",
      "428931       126    32767  0.002090   0.000149\n",
      "\n",
      "[428932 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_joined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
